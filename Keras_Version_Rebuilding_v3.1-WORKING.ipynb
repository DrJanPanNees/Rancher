{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "YKYageCw6Xrq",
    "outputId": "98d4f397-b370-4f44-c38e-aa5bc2c7f381"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow imported\n",
      "====================================================================================================\n",
      "Copy rights: Dr. Jan P. Nees, PhD.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Lib finished importing\n",
      "Dataset Loaded\n",
      "\n",
      "Models has been loaded\n",
      "Methods has been loaded\n",
      "\n",
      "Load finished\n",
      "------- Data processing -------------\n",
      "tokenizer loaded\n",
      "tensor is (rows, sentence length padded)\n",
      "target_tensor.shape:  (8000, 143)\n",
      "input_tensor.shape:  (8000, 146)\n",
      "6400 6400 1600 1600\n",
      "Model loaded\n",
      "Input Language; index to word mapping\n",
      "3 ----> <start>\n",
      "21 ----> med\n",
      "92 ----> hensyn\n",
      "12 ----> til\n",
      "8 ----> det\n",
      "146 ----> andet\n",
      "82 ----> forslag\n",
      "430 ----> forstaar\n",
      "34 ----> kommissionen\n",
      "1542 ----> oensket\n",
      "22 ----> om\n",
      "1 ----> ,\n",
      "5 ----> at\n",
      "8 ----> det\n",
      "27 ----> skal\n",
      "36 ----> vaere\n",
      "144 ----> klart\n",
      "1 ----> ,\n",
      "64 ----> hvad\n",
      "15 ----> der\n",
      "13007 ----> forstaas\n",
      "40 ----> ved\n",
      "13 ----> en\n",
      "4994 ----> selvstaendig\n",
      "2 ----> .\n",
      "34 ----> kommissionen\n",
      "156 ----> kommer\n",
      "21 ----> med\n",
      "13 ----> en\n",
      "407 ----> loesning\n",
      "11 ----> af\n",
      "30 ----> dette\n",
      "391 ----> problem\n",
      "7 ----> i\n",
      "8 ----> det\n",
      "1729 ----> aendrede\n",
      "82 ----> forslag\n",
      "2 ----> .\n",
      "4 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "3 ----> <start>\n",
      "22 ----> as\n",
      "199 ----> far\n",
      "22 ----> as\n",
      "1 ----> the\n",
      "281 ----> second\n",
      "157 ----> proposal\n",
      "11 ----> is\n",
      "235 ----> concerned\n",
      "2 ----> ,\n",
      "1 ----> the\n",
      "29 ----> commission\n",
      "8619 ----> appreciates\n",
      "1 ----> the\n",
      "329 ----> wish\n",
      "12 ----> that\n",
      "18 ----> it\n",
      "39 ----> should\n",
      "17 ----> be\n",
      "156 ----> clear\n",
      "54 ----> what\n",
      "11 ----> is\n",
      "2577 ----> meant\n",
      "27 ----> by\n",
      "2033 ----> someone\n",
      "71 ----> who\n",
      "11 ----> is\n",
      "970 ----> self\n",
      "1046 ----> employed\n",
      "8 ----> and\n",
      "31 ----> would\n",
      "79 ----> therefore\n",
      "49 ----> like\n",
      "7 ----> to\n",
      "1402 ----> resolve\n",
      "13 ----> this\n",
      "113 ----> issue\n",
      "9 ----> in\n",
      "1 ----> the\n",
      "1214 ----> amended\n",
      "157 ----> proposal\n",
      "5 ----> .\n",
      "4 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "# === NOTES ====\n",
    "# 1) If model already generated, load it.\n",
    "# 2) Remeber to run ness. tokenizers\n",
    "\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "#Crach COLAB to get more RAM\n",
    "'''\n",
    "d=[]\n",
    "while(1):\n",
    "  d.append('1')\n",
    "'''\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print('Tensorflow imported')\n",
    "#tf.enable_eager_execution()\n",
    "#tf.executing_eagerly()\n",
    "#================== Copy Rights ==================\n",
    "print('='*100)\n",
    "print('Copy rights: Dr. Jan P. Nees, PhD.')\n",
    "print('='*100)\n",
    "#================== Import libraries ==================\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "#from tensorflow import keras\n",
    "\n",
    "print('='*100)\n",
    "''' \n",
    "versionTF = tf.__version__\n",
    "\n",
    "if versionTF != '2.0.0b1':\n",
    "  !pip install tensorflow==2.0.0b1\n",
    "else:\n",
    "  print(versionTF)\n",
    "\n",
    "#!pip install tensorflow-probability==0.8.0rc0\n",
    "!pip install tensorflow_probability==0.8.0rc0 --user --upgrade\n",
    "'''\n",
    "print('='*100)\n",
    "\n",
    "#from keras.preprocessing.text import Tokenizer\n",
    "#from keras.preprocessing.sequence import pad_sequences\n",
    "#from keras.models import Model\n",
    "#from keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional\n",
    "#from keras.layers.merge import concatenate\n",
    "#from keras.layers.embeddings import Embedding\n",
    "#from keras.optimizers import Adam, adam\n",
    "#from keras.losses import sparse_categorical_crossentropy\n",
    "import matplotlib.pyplot as plt\n",
    "#from keras.utils import plot_model\n",
    "#from keras.models import load_model\n",
    "import unicodedata\n",
    "import re\n",
    "import io\n",
    "#from keras import Sequential\n",
    "#from keras.layers import GRU, RepeatVector, TimeDistributed, Dense, LSTM, Input\n",
    "#from keras.losses import sparse_categorical_crossentropy\n",
    "#from keras.callbacks import TensorBoard\n",
    "from time import time\n",
    "import matplotlib.ticker as ticker\n",
    "#from nltk.tokenize import sent_tokenize\n",
    "#from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import collections\n",
    "\n",
    "\n",
    "\n",
    "FLASK_DEBUG=0\n",
    "\n",
    "print ('Lib finished importing')\n",
    "\n",
    "#================== Methods ==================\n",
    "#---------Tokenizer Method -----------------------------------\n",
    "# ------ Main issues: Not sure if it does it correctly to DK and DE sentences. --------\n",
    "\n",
    "#================== ======================================== ==================\n",
    "#english_reader = load_data('europarl-v8.en')\n",
    "#danish_reader = load_data('europarl-v8.da')\n",
    "\n",
    "print('Dataset Loaded')\n",
    "\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "\n",
    "    # creating a space between a word and the punctuation following it\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    #w = re.sub(r\"[å]+\", \"aa\", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "\n",
    "    w = w.rstrip().strip()\n",
    "\n",
    "    # adding a start and an end token to the sentence\n",
    "    # so that the model know when to start and stop predicting.\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "def load_data_v2(path):\n",
    "    \n",
    "    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "    #w = preprocess_sentence(line) for line in lines\n",
    "    #return w\n",
    "    w = [preprocess_sentence(line)  for line in lines[8000:16000]] #<----------- How many lines of sentences\n",
    "        #print(w)\n",
    "            #data = preprocess_sentence(lines)\n",
    "            #preprocess_sentence(data) \n",
    "\n",
    "    return w\n",
    "#----------------------------------------------------------------------\n",
    "print(\"\"\"\n",
    "Models has been loaded\n",
    "Methods has been loaded\n",
    "\"\"\")\n",
    "\n",
    "# ==== Colab Path ====\n",
    "#english_reader = load_data_v2('drive/My Drive/txt/europarl-v7.da-en.en')\n",
    "#danish_reader = load_data_v2('drive/My Drive/txt/europarl-v7.da-en.da')\n",
    "\n",
    "# === EURO PARL ===\n",
    "# ==== Local Path ====\n",
    "english_reader = load_data_v2('europarl-v7.da-en.en')\n",
    "danish_reader = load_data_v2('europarl-v7.da-en.da')\n",
    "print('Load finished')\n",
    "\n",
    "# === ANKI ====\n",
    "#english_reader = load_data_v2('UK.txt')\n",
    "#danish_reader = load_data_v2('DK.txt')\n",
    "\n",
    "#=============================================================================\n",
    "#================= TEXT ANALYSIS HERE ========================================\n",
    "#=============================================================================\n",
    "\n",
    "#------------- DATA processing-----------------\n",
    "print('------- Data processing -------------')\n",
    "\n",
    "def max_length(tensor):\n",
    "    return max(len(t) for t in tensor)\n",
    "\n",
    "def tokenize(lang):\n",
    "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "\n",
    "  lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "\n",
    "  return tensor, lang_tokenizer\n",
    "\n",
    "print('tokenizer loaded')\n",
    "\n",
    "target_tensor, targ_lang = tokenize(english_reader)\n",
    "input_tensor, inp_lang = tokenize(danish_reader)\n",
    "\n",
    "print(\"tensor is (rows, sentence length padded)\")\n",
    "print('target_tensor.shape: ', target_tensor.shape) # <--- (8000, 143)\n",
    "print('input_tensor.shape: ', input_tensor.shape)   # <--- (8000, 146)\n",
    "\n",
    "# Creating training and validation sets using an 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# Show length\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val)) # 6400 6400 1600 1600 \n",
    "\n",
    "def convert(lang, tensor):\n",
    "  for t in tensor:\n",
    "    if t!=0:\n",
    "      print (\"%d ----> %s\" % (t, lang.index_word[t]))\n",
    "    \n",
    "print('Model loaded')\n",
    "\n",
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[1])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6400, 146)\n",
      "\n",
      "      Shape (19,18,5)\n",
      "      axis 0 = 19\n",
      "      axis 1 = 18\n",
      "      axis 2 = 5\n",
      "      axis -1 = last axis\n",
      "      \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' \\ninput_tensor_train_norm = tf.keras.utils.normalize(input_tensor_train, axis=-1)\\ntarget_tensor_train_norm = tf.keras.utils.normalize(target_tensor_train, axis=-1)\\nprint(input_tensor_train[0])\\nprint(input_tensor_train_norm[0])\\nprint(np.max(input_tensor_train_norm[0]))\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#===================================\n",
    "# Test Normalization vs Embedding??\n",
    "#===================================\n",
    "print(input_tensor_train.shape)\n",
    "print(\"\"\"\n",
    "      Shape (19,18,5)\n",
    "      axis 0 = 19\n",
    "      axis 1 = 18\n",
    "      axis 2 = 5\n",
    "      axis -1 = last axis\n",
    "      \"\"\"\n",
    "      )\n",
    "''' \n",
    "input_tensor_train_norm = tf.keras.utils.normalize(input_tensor_train, axis=-1)\n",
    "target_tensor_train_norm = tf.keras.utils.normalize(target_tensor_train, axis=-1)\n",
    "print(input_tensor_train[0])\n",
    "print(input_tensor_train_norm[0])\n",
    "print(np.max(input_tensor_train_norm[0]))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "3 ----> <start>\n",
      "8 ----> det\n",
      "9 ----> er\n",
      "165 ----> dog\n",
      "120 ----> helt\n",
      "144 ----> klart\n",
      "1 ----> ,\n",
      "5 ----> at\n",
      "49 ----> disse\n",
      "3036 ----> stoetteordninger\n",
      "80 ----> boer\n",
      "2206 ----> kontrolleres\n",
      "1 ----> ,\n",
      "6 ----> og\n",
      "8 ----> det\n",
      "9 ----> er\n",
      "13 ----> en\n",
      "394 ----> opgave\n",
      "1 ----> ,\n",
      "15 ----> der\n",
      "3708 ----> paahviler\n",
      "39 ----> europa\n",
      "34 ----> kommissionen\n",
      "2 ----> .\n",
      "4 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "3 ----> <start>\n",
      "307 ----> clearly\n",
      "544 ----> though\n",
      "2 ----> ,\n",
      "18 ----> it\n",
      "42 ----> must\n",
      "17 ----> be\n",
      "2507 ----> monitored\n",
      "2 ----> ,\n",
      "10 ----> a\n",
      "651 ----> task\n",
      "20 ----> which\n",
      "1535 ----> falls\n",
      "7 ----> to\n",
      "1 ----> the\n",
      "28 ----> european\n",
      "29 ----> commission\n",
      "5 ----> .\n",
      "4 ----> <end>\n",
      "====================================================================================================\n",
      "len(target_tensor_train):  6400\n",
      "len(target_tensor_val):  1600\n",
      "target_tensor.shape[1]:  143\n",
      "input_tensor.shape[1]:  146\n",
      "Vocab size DK:  14407\n",
      "Vocab size UK:  9306\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[3])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[3])\n",
    "print('='*100)\n",
    "\n",
    "#===============================================================================\n",
    "#===============================================================================\n",
    "print('len(target_tensor_train): ', len(target_tensor_train))\n",
    "print('len(target_tensor_val): ', len(target_tensor_val))\n",
    "\n",
    "print('target_tensor.shape[1]: ', target_tensor.shape[1])\n",
    "print('input_tensor.shape[1]: ', input_tensor.shape[1])\n",
    "\n",
    "\n",
    "\n",
    "#n_input = len(target_tensor_val)    #<--- 6400\n",
    "#n_output = len(target_tensor_train) #<--- 1600\n",
    "\n",
    "n_input = input_tensor.shape[1] # (8000, 143)\n",
    "n_output = target_tensor.shape[1]   # (8000, 146)\n",
    "#===============================================================================\n",
    "\n",
    "n_units = 4096 #what should this be?\n",
    "\n",
    "n_steps = target_tensor.shape[0] # ---- 8000\n",
    "\n",
    "vocab_dk = len(inp_lang.word_index)+1\n",
    "vocab_uk = len(targ_lang.word_index)+1 \n",
    "\n",
    "embedding_dim = 256\n",
    "BATCH_SIZE = 64\n",
    "hidden = 0\n",
    "\n",
    "print('Vocab size DK: ', vocab_dk)\n",
    "print('Vocab size UK: ', vocab_uk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===============================================================================\n",
    "#input_dim: This is the size of the vocabulary in the text data. \n",
    "# For example, if your data is integer encoded to values between 0-10, then \n",
    "# the size of the vocabulary would be 11 words.\n",
    "\n",
    "#output_dim: This is the size of the vector space in which words will be \n",
    "# embedded. It defines the size of the output vectors from this layer for \n",
    "# each word. For example, it could be 32 or 100 or even larger.\n",
    "\n",
    "#input_length: This is the length of input sequences, as you would define for \n",
    "# any input layer of a Keras model. For example, if all of your input \n",
    "# documents are comprised of 1000 words, this would be 1000.\n",
    "# example: model.add(Embedding(vocab_size, 8, input_length=max_length))\n",
    "#==============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "colab_type": "code",
    "id": "rl5fp8bQAl5i",
    "outputId": "83215df6-8e09-4ed7-a7f2-ad32c784cf3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Encoder_Input (InputLayer)      [(None, 146)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_Input (InputLayer)      [(None, 143)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Encod_Embed (Embedding)         (None, 146, 146)     2103422     Encoder_Input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Decod_Embed (Embedding)         (None, 143, 143)     1330758     Decoder_Input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "LSTM_1 (LSTM)                   [(None, 146, 4096),  69517312    Encod_Embed[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_LSTM (LSTM)             [(None, 143, 4096),  69468160    Decod_Embed[0][0]                \n",
      "                                                                 LSTM_1[0][1]                     \n",
      "                                                                 LSTM_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_Dense (Dense)           (None, 143, 143)     585871      Decoder_LSTM[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 143,005,523\n",
      "Trainable params: 143,005,523\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Time taken sec:\n",
      " 18540.22084236145\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "#===============================================================================\n",
    "encoder_inputs = tf.keras.layers.Input(shape=(n_input), name='Encoder_Input')\n",
    "\n",
    "encod_embed = tf.keras.layers.Embedding(output_dim=n_input, input_dim=vocab_dk, input_length=vocab_dk, name='Encod_Embed') # <- is this right??\n",
    "enc_lstm = tf.keras.layers.LSTM(n_units, return_state = True, return_sequences=True, name='LSTM_1')\n",
    "#===============================================================================\n",
    "encd_embed_out = encod_embed(encoder_inputs)\n",
    "enc_out, enc_h, enc_c = enc_lstm(encd_embed_out)\n",
    "enc_states = [enc_h, enc_c]\n",
    "\n",
    "decoder_inputs = tf.keras.layers.Input(shape=(n_output), name='Decoder_Input')\n",
    "\n",
    "decod_embed = tf.keras.layers.Embedding(output_dim=n_output, input_dim=vocab_uk, name='Decod_Embed')\n",
    "dec_lstm = tf.keras.layers.LSTM(n_units, return_state = True, return_sequences=True, name='Decoder_LSTM') # Build the LSTM layer\n",
    "decoder_output = tf.keras.layers.Dense(n_output, activation='softmax', name='Decoder_Dense')\n",
    "\n",
    "decod_embed_out = decod_embed(decoder_inputs)\n",
    "dec_x, dec_h, dec_c = dec_lstm(decod_embed_out, initial_state=enc_states) # Feed to the LSTM layer\n",
    "dec_states = [dec_h, dec_c] # Seperate out the states\n",
    "    \n",
    "decoder_out_dense = decoder_output(dec_x)\n",
    "#===============================================================================\n",
    "model_test_NoClass = tf.keras.Model(inputs=[encoder_inputs, decoder_inputs], outputs=decoder_out_dense)\n",
    "#===============================================================================\n",
    "#           Compile\n",
    "#===============================================================================\n",
    "model_test_NoClass.compile(optimizer='adam', \n",
    "                           loss='categorical_crossentropy', \n",
    "                           metrics=['accuracy']) \n",
    "                                # <- WORKS!!!!\n",
    "#===============================================================================\n",
    "model_test_NoClass.summary()\n",
    "print('Time taken sec:\\n', ((time.time()-start)*60))\n",
    "#tf.keras.utils.plot_model(model_test_NoClass, show_shapes=True)\n",
    "#tf.keras.utils.plot_model(model_test_NoClass, show_shapes=True,  to_file='Enc_Decoder_NoClass_v2.png')\n",
    "\n",
    "#===============================================================================\n",
    "#tensor board test\n",
    "#!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorboard setup finished\n"
     ]
    }
   ],
   "source": [
    "#%load_ext tensorboard\n",
    "\n",
    "log_dir = \"logs\\\\fit\\\\\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "print(\"Tensorboard setup finished\")\n",
    "\n",
    "# tensorboard does not work with tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 143)\n",
      "(8000, 146)\n",
      "(1600, 146)\n",
      "(1600, 143)\n",
      "Does the shape and batch size work?:  133.33333333333334\n",
      "(1600, 143, 1)\n",
      "Starting Evaluation modelling.\n",
      "Eval the model apparently can only handle verbose =1\n",
      "verbose 0 = silence, 1 = progress bar, 2 = per epocch\n",
      "1600/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 2408s 2s/sample - loss: 0.0000e+00 - accuracy: 0.0077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval model finished\n",
      "accuracy: 0.77%\n",
      "Metrics:  ['loss', 'accuracy']\n",
      "Input names:  ['Encoder_Input', 'Decoder_Input']\n",
      "Output names:  ['Decoder_Dense']\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "#===============================================================================\n",
    "batchsize = 60\n",
    "print(target_tensor.shape)\n",
    "print(input_tensor.shape)\n",
    "print(input_tensor_val.shape)\n",
    "print(target_tensor_val.shape)\n",
    "inp_tensor_shape_val = input_tensor_val.shape[0]\n",
    "print('Does the shape and batch size work?: ', input_tensor.shape[0] / batchsize)\n",
    "#===============================================================================\n",
    "emptyContainer2 = tf.zeros([inp_tensor_shape_val, n_output, 1], dtype=tf.dtypes.float64)\n",
    "print(emptyContainer2.shape) # <--- shape = (8000, 143, 1)\n",
    "\n",
    "print('Starting Evaluation modelling.')\n",
    "print('Eval the model apparently can only handle verbose =1')\n",
    "print('verbose 0 = silence, 1 = progress bar, 2 = per epocch')\n",
    "\n",
    "score = model_test_NoClass.evaluate([input_tensor_val, target_tensor_val], \n",
    "                                    emptyContainer2,  \n",
    "                                    batch_size=batchsize, \n",
    "                                    verbose=1,\n",
    "                                    callbacks=[tensorboard_callback]\n",
    "                                   )\n",
    "print('Eval model finished')\n",
    "#===============================================================================\n",
    "print(\"%s: %.2f%%\" % (model_test_NoClass.metrics_names[1], score[1]*100))\n",
    "print('Metrics: ', model_test_NoClass.metrics_names)\n",
    "print('Input names: ', model_test_NoClass.input_names)\n",
    "print('Output names: ', model_test_NoClass.output_names)\n",
    "print('='*100)\n",
    "#===============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_dir = \"logs\\\\fit\\\\\"\n",
    "\n",
    "#!tensorboard --logdir log_dir\n",
    "#%tensorboard --logdir {log_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "id": "43Jj00zAjA4p",
    "outputId": "2cbd427e-c329-4463-ad14-ef6d64c8866e"
   },
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "# input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val  = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "# uk_training_reshape -> is: input_tensor_train\n",
    "# dk_training_reshape -> is: target_tensor_train\n",
    "# uk_test_reshape -> is: input_tensor_val\n",
    "# dk_test_reshape -> is: target_tensor_val\n",
    "# ==============================================================================\n",
    "# Current error - needs to be reshaped into 3ndim. How can Google avoid this? Embedding layer??\n",
    "\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# ========== FIT MODEL =========================================================\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='loss', mode='min')\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "con_value = input_tensor_train.shape[0]\n",
    "emptyContainer2 = tf.zeros([con_value, n_output, 1], dtype=tf.dtypes.float32, name=None)\n",
    "\n",
    "model_test_NoClass.fit([input_tensor_train, target_tensor_train], \n",
    "                       emptyContainer2, \n",
    "                       batch_size = 30, \n",
    "                       epochs=10, \n",
    "                       verbose=1, # Epochs have to be set to minimum 10\n",
    "                       validation_split=0.3,\n",
    "                       callbacks=[tensorboard_callback]\n",
    "                      ) # Uses Train data\n",
    "#===============================================================================\n",
    "#===============================================================================\n",
    "plt.plot(model_test_NoClass.history.history['loss'])\n",
    "plt.plot(model_test_NoClass.history.history['val_loss'])\n",
    "plt.title('model train vs validation loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()\n",
    "#===============================================================================\n",
    "print('Time taken sec:\\n', ((time.time()-start)*60))\n",
    "#===============================================================================\n",
    "# save model and architecture to single file\n",
    "model_test_NoClass.save(\"Google_Rebuild_FitModel_v8000_ep3_v2.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "#===============================================================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_loss, val_acc = model_test_NoClass.evaluate([input_tensor_val, target_tensor_val], emptyContainer2)\n",
    "#print(val_loss)\n",
    "#print(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emptyContainer3 = tf.zeros([inp_tensor_shape_val, n_output, 1], dtype=tf.dtypes.float64)\n",
    "score = model_test_NoClass.evaluate([input_tensor_val, target_tensor_val], emptyContainer3, verbose=1)\n",
    "print('Score after training: \\n', model_test_NoClass.metrics_names, score)\n",
    "print('='*200)\n",
    "#print('optimizer: ', optimizer)\n",
    "print('Score after training: \\n', model_test_NoClass.metrics_names, score)\n",
    "print(\"%s: %.2f%%\" % (model_test_NoClass.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "M-SgOrQ1bM7a",
    "outputId": "570d3275-9b60-4a7c-f126-a618f34343c6"
   },
   "outputs": [],
   "source": [
    "# How to see if the restore model works???\n",
    "# See that now its empty, and after below restore, its been populated?\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 975
    },
    "colab_type": "code",
    "id": "1eBY3-SmuVMe",
    "outputId": "c0ea41b3-f4d8-4e43-9ee2-14a483b4770f"
   },
   "outputs": [],
   "source": [
    "#========================================\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! LOAD ME\n",
    "#========================================\n",
    "# Remeber to load basic elements, then run this ...\n",
    "# Then I don t need to train again .... Again the 28 hrs model could be run at my own system.\n",
    "#\n",
    "#========================================\n",
    "# OLD model\n",
    "#model_restored = tf.keras.models.load_model('drive/My Drive/txt/Google_Rebuild_FitModel.h5')\n",
    "#emptyContainer4 = tf.zeros([n_steps, n_output, 1], dtype=tf.dtypes.float32, name=None) \n",
    "# NEW model\n",
    "model_restored = tf.keras.models.load_model('Google_Rebuild_FitModel_v8000_ep3.h5')\n",
    "# summarize model.\n",
    "model_restored.summary()\n",
    "#========================================\n",
    "#score = model_restored.evaluate([input_tensor_train, target_tensor_train], emptyContainer2, verbose=1)\n",
    "#print(\"%s: %.2f%%\" % (model_restored.metrics_names[1], score[1]*100))\n",
    "tf.keras.utils.plot_model(model_test_NoClass, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "MgoAm8vAPO_n",
    "outputId": "006e9c38-e5c8-4be8-b47e-c7bbcd630aec"
   },
   "outputs": [],
   "source": [
    "#===============================================================================\n",
    "#===============================================================================\n",
    "# Inference models for testing\n",
    "#===============================================================================\n",
    "# This is a strange piece of code, the fitting has already been run.\n",
    "# So what is the point with the below?\n",
    "# train_test.fit([input_tensor_train_res, target_tensor_train_res], emptyContainer2, epochs=2, verbose=1, callbacks=[es])\n",
    "#===============================================================================\n",
    "\n",
    "#===============================================================================\n",
    "# REUSE CODE\n",
    "#===============================================================================\n",
    "\n",
    "print('len(target_tensor_train): ', len(target_tensor_train))\n",
    "print('len(target_tensor_val): ', len(target_tensor_val))\n",
    "\n",
    "print('target_tensor.shape[1]: ', target_tensor.shape[1])\n",
    "print('input_tensor.shape[1]: ', input_tensor.shape[1])\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "#n_input = len(target_tensor_val)    #<--- 6400\n",
    "#n_output = len(target_tensor_train) #<--- 1600\n",
    "\n",
    "n_input = input_tensor.shape[1] # (8000, 143)\n",
    "n_output = target_tensor.shape[1]   # (8000, 146)\n",
    "\n",
    "n_units = 1024\n",
    "optimizer = 'adam'\n",
    "loss_unit = 'mean_squared_error'\n",
    "n_steps = target_tensor.shape[0] # ---- 8000\n",
    "\n",
    "vocab_dk = len(inp_lang.word_index)\n",
    "vocab_uk = len(targ_lang.word_index) \n",
    "\n",
    "print('Vocab size DK: ', vocab_dk)\n",
    "print('Vocab size DK: ', vocab_uk)\n",
    "print('N_output: ', n_output)\n",
    "\n",
    "#===============================================================================\n",
    "#===============================================================================\n",
    "# EXPERIMENTAL CODE\n",
    "#===============================================================================\n",
    "#===============================================================================\n",
    "#model_restored.\n",
    "#===============================================================================\n",
    "print('n_units: ', n_units)\n",
    "\n",
    "#===============================================================================\n",
    "# Encoder inference model\n",
    "encoder_model_inf = tf.keras.Model(encoder_inputs, enc_states, name='Encoder Model') # works even with Embedding\n",
    "print('='*100)\n",
    "encoder_model_inf.summary()\n",
    "\n",
    "# Embedding layer?\n",
    "#===============================================================================\n",
    "# Decoder inference model\n",
    "#shape should be ???\n",
    "decoder_state_input_h = tf.keras.layers.Input(shape=(n_units,)) # Empty Container (1024)\n",
    "decoder_state_input_c = tf.keras.layers.Input(shape=(n_units,)) # Empty Container (1024)\n",
    "decoder_input_states = [decoder_state_input_h, decoder_state_input_c] # Connects the two containers: shape=(None, 1024)\n",
    "final_dex = decod_embed(decoder_inputs)\n",
    "print(decoder_input_states)\n",
    "# Embedding layer\n",
    "#Embed_inf = decoder_inputs\n",
    "\n",
    "#===================================\n",
    "# Below takes DEC_LSTM and feed decoder_inputs and set the empty containers.\n",
    "decoder_out2, decoder_h2, decoder_c2 = dec_lstm(final_dex, \n",
    "                                                 initial_state=decoder_input_states) # why does this fail?, Shape (143, None) <- where?\n",
    "\n",
    "decoder_states2 = [decoder_h2, decoder_c2]\n",
    "decoder_outputs2 = decoder_output(decoder_out2)\n",
    "#===============================================================================\n",
    "# Decoder inference model\n",
    "decoder_model_inf = tf.keras.Model(inputs=[decoder_inputs] + decoder_input_states, # <--------- AS ALWAYS IS THE NAMING ISSUES\n",
    "                          outputs=[decoder_outputs2] + decoder_states2 )\n",
    "#===============================================================================\n",
    "\n",
    "print('='*100)\n",
    "decoder_model_inf.summary()\n",
    "print('='*100)\n",
    "\n",
    "tf.keras.utils.plot_model(encoder_model_inf, show_shapes=True, to_file='Infer_Encoder_NoClass.png')\n",
    "tf.keras.utils.plot_model(decoder_model_inf, show_shapes=True,  to_file='Infer_Decoder_NoClass.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "id": "sf_dEdhnrRTB",
    "outputId": "ac1612ad-fa99-4956-ee94-0271621fd030"
   },
   "outputs": [],
   "source": [
    "\n",
    "#===============================================================================\n",
    "#===============================================================================\n",
    "#========== TESTING PREDICTION ================ ================================\n",
    "# ========= DK 2 UK Translation =============== ================================\n",
    "# We want to feed it DK sentence and let it translation into UK\n",
    "# What would the final version be for the research paper???? UK to Many???\n",
    "#===============================================================================\n",
    "# So far so good ... now how to Predict and get out the stuff that I want?\n",
    "\n",
    "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)\n",
    "\n",
    "print('='*100)\n",
    "text_testing_dk = 'Det har du rigtig godt af'\n",
    "\n",
    "#add <start> x <end>\n",
    "sentence = preprocess_sentence(text_testing_dk)\n",
    "print('sentence: ', sentence)\n",
    "print('='*100)\n",
    "\n",
    "#to index:  [3, 457, 22, 3560, 4]\n",
    "inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "print('to index: ', inputs) \n",
    "print('='*100)\n",
    "convert(inp_lang, inputs)\n",
    "\n",
    "# create the Matrix\n",
    "inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_length_inp, padding='post')\n",
    "inputs = tf.convert_to_tensor(inputs)\n",
    "print (inputs)\n",
    "\n",
    "print('Starting to send to NN')\n",
    "print('='*100)\n",
    "\n",
    "#units = 1024\n",
    "#hidden = [tf.zeros((1, units))]\n",
    "#enc_out, enc_hidden = encoder_model_inf(inputs, hidden)\n",
    "\n",
    "#dec_hidden = enc_hidden\n",
    "#print(dec_hidden)\n",
    "#===============================================================================\n",
    "# Need to make it into 3D.\n",
    "#===============================================================================\n",
    "print('inputs.shape: ', inputs.shape) # (1,146)\n",
    "inputs_re = tf.reshape(inputs,(1,max_length_inp))\n",
    "#inputs_re = inputs.reshape(1,max_length_targ,1) #  <---- should this shape match something?\n",
    "print('inputs_re.shape: ', inputs_re.shape)\n",
    "#print('the inputs looks like: \\n', inputs_re)\n",
    "print('='*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(target_tensor.shape[1])\n",
    "print(input_tensor.shape[1])\n",
    "print(max_length_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "E2_YzIrR0sMn",
    "outputId": "6ba4ad38-efc3-41c4-faac-f59469635a52"
   },
   "outputs": [],
   "source": [
    "#target_tensor.shape[1]:  12\n",
    "#input_tensor.shape[1]:  13\n",
    "\n",
    "print('targ lang end: ', targ_lang.index_word[4] == '<end>')\n",
    "\n",
    "states_val_v2 = encoder_model_inf.predict(inputs_re) # inputs shape (146,1)\n",
    "print(states_val_v2)\n",
    "print('='*100)\n",
    "target_seq = np.zeros((1, max_length_targ)) # shape (1, 143) <--- WORKS\n",
    "target_seq[0,0] = targ_lang.word_index['<start>']\n",
    "print(target_seq.transpose)\n",
    "print('='*100)\n",
    "print('target seq: ', target_seq.shape)\n",
    "\n",
    "\n",
    "stop_con = False\n",
    "decoded_sen = ''\n",
    "while not stop_con:\n",
    "   prediction, decoder_h, decoder_c = decoder_model_inf.predict(x=[target_seq] + states_val_v2) # <- do this 143 times, why?\n",
    "   \n",
    "   sampled_token_index = np.argmax(prediction[0,-1,:])\n",
    "   sampled_char = targ_lang.index_word[sampled_token_index]\n",
    "   decoded_sen += ' ' + sampled_char\n",
    "   print(decoded_sen)\n",
    "   print('='*100)\n",
    "\n",
    "   if(len(decoded_sen) > max_length_targ):\n",
    "     stop_con = True\n",
    "   target_seq = np.zeros((1,12)) # <--- WORKS, well to some degree...\n",
    "   target_seq[0,0] = sampled_token_index\n",
    "   #states_val_v2 = [h,c]\n",
    "\n",
    "print(decoded_sen)\n",
    "print('='*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "colab_type": "code",
    "id": "sRQvl8Z5DZw0",
    "outputId": "8eadd8bc-6d2d-4a5f-e9fe-b78d1677f164"
   },
   "outputs": [],
   "source": [
    "print('targ lang end: ', targ_lang.index_word[4] == '<end>')\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "''' \n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())\n",
    "\n",
    "\n",
    "states_val_v2 = encoder_model_inf.predict(inputs)\n",
    "print(states_val_v2)\n",
    "target_seq = np.zeros((143,1))\n",
    "target_seq[0,0] = targ_lang.word_index['<start>']\n",
    "print(target_seq.transpose)\n",
    "\n",
    "stop_con = False\n",
    "decoded_sen = ''\n",
    "while not stop_con:\n",
    "   prediction, decoder_h, decoder_c = decoder_model_inf.predict(x=[target_seq] + states_val_v2) # <- do this 143 times, why?\n",
    "\n",
    "   sampled_token_index = np.argmax(prediction[0,-1,:])\n",
    "   sampled_char = targ_lang.index_word[sampled_token_index]\n",
    "   decoded_sen += ' ' + sampled_char\n",
    "   print(decoded_sen)\n",
    "\n",
    "\n",
    "\n",
    "   if(len(decoded_sen) > 143):\n",
    "     stop_con = True\n",
    "   target_seq = np.zeros((1,1))\n",
    "   target_seq[0,0] = sampled_token_index\n",
    "   #states_val_v2 = [h,c]\n",
    "\n",
    "print(decoded_sen)\n",
    "\n",
    "\n",
    "#for t in range(1, max_length_targ): # does this mean 1-146 <- yes: \"range(min_value, max_value)\"\n",
    "#===============================================================================\n",
    "# So here we take the statevalues from the Dncoder, and try to predict these in the Decoder\n",
    "# We then take the prediction/decoder out - and feed it through a argmax to find the max values.\n",
    "\n",
    "#    prediction, decoder_h, decoder_c = decoder_model_inf.predict(x=[decoder_inp] + states_val) # <- do this 143 times, why?\n",
    "\n",
    "\n",
    "  #print('prediction.tolist: \\n', prediction)\n",
    "  #print(t, ':', 'prediction[1:1,:]: \\n', prediction[:,:t])\n",
    "  #print('prediction shap: \\n', prediction.shape) # (1, 143, 143)\n",
    "  #print('='*100)\n",
    "\n",
    "  #predict_id = tf.math.argmax(input=prediction[:,:t], axis=1)\n",
    "  #predict_id = np.argmax(prediction[:,:t])\n",
    "  #print(t, ':', predict_id)\n",
    "'''\n",
    "\n",
    "'''  \n",
    "  #predict_id = tfp.distributions.Multinomial(tf.math.exp(prediction), probs=prediction)[0][0]\n",
    "\n",
    "  #\n",
    "  print('predict_id = tf.argmax: \\n', predict_id)\n",
    "  #result += targ_lang.index_word[predict_id] + ' '\n",
    "\n",
    "  if targ_lang.index_word[predict_id] == '<end>':\n",
    "    print('result: ', result)\n",
    "    print('finsihed')\n",
    "\n",
    "  print('result: ', result)\n",
    "  #prediction_id = tf.exp(prediction)[0][0].numpy()\n",
    "  #print(prediction_id)\n",
    "  \n",
    "  #print(\"prediction: \\n\", prediction.shape) # <----- (1,143,143) ---- there are different numbers inside it, I guess we need a loop to get, WHY inside loop???\n",
    "  #print('np.argmax(prediction): \\n', np.argmax(prediction)) #<--- find the highest number in Matrix.\n",
    "  #print('predict_id = tf.argmax: \\n', tf.argmax(decoder_out[0:142,:]).numpy()) # Spit out an array with many values, would make sense. [:] <- [from:to]\n",
    "  #for t in range(1,2):\n",
    "   # print('prediction[:,:-1]: \\n', prediction[:-1,:])\n",
    "\n",
    "\n",
    "  #max_val_index = np.argmax(prediction[0,-1,:]) # <- what does this Matrix slicing do??? [R,C,]\n",
    "  #sampled_fra_char = targ_lang.index_word[max_val_index]\n",
    "\n",
    "  #while t < 2:\n",
    "   # print(t, ' ', decoder_out)\n",
    "\n",
    "  #print(sampled_fra_char)\n",
    "\n",
    "  #translated_sent += sampled_fra_char\n",
    "\n",
    "\n",
    " \n",
    "  #print('decoder_out.shape: ', decoder_out.shape)\n",
    "\n",
    "  #print('='*100)\n",
    "  #print('Decoder out in 0: \\n', tf.argmax(decoder_out[0]))\n",
    "  #predict_id = tf.argmax(decoder_out[0,-1,:]).numpy() # Spit out an array with many values, would make sense.\n",
    "  #print('='*100)\n",
    "  \n",
    "  #print(t, ' prediction: \\n', predict_id)\n",
    "  #print('='*100)\n",
    "  \n",
    "  #translated_sent += predict_id\n",
    "\n",
    "  #predict_id = np.argmax(decoder_out[0]) # Spit out one value - does not make sense\n",
    "  #translated_sent += targ_lang.index_word[predict_id] + ' '\n",
    "  \n",
    "  #if targ_lang.index_word[predict_id] == '<end>':\n",
    "   # print('finsihed')\n",
    "\n",
    "\n",
    "#print('prediction: \\n', predict_id)\n",
    "#print('result: \\n', translated_sent)\n",
    "'''\n",
    "\n",
    "''' \n",
    "print(max_val_index)\n",
    "print('*'*100)\n",
    "print(tf.math.argmax(input=decoder_out))\n",
    "print('='*100)\n",
    "print('decoder shape: \\n', decoder_out.shape)\n",
    "'''\n",
    "\n",
    "# Then we pass this max_val into an ARGMAX to find the max value.\n",
    "#===============================================================================\n",
    "#max_val = np.argmax(decoder_out[0,-1,:])\n",
    "#sampled_char = targ_lang.index_word[max_val] # <---- or word_index ??? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gZJtDNFSuaOa"
   },
   "outputs": [],
   "source": [
    "# function for plotting the attention weights\n",
    "def plot_attention(sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "    \n",
    "    fontdict = {'fontsize': 14}\n",
    "    \n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# We first need to find a connection in the Encoder\n",
    "\n",
    "# Test\n",
    "#(inputs=[encoder_inputs, decoder_inputs], outputs=decoder_out_dense)\n",
    "\n",
    "#inputs_reshape = inputs.reshape(inputs.shape[0],inputs.shape[1],1)\n",
    "\n",
    "#model_restored.predict([inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7KqW1lcLWNEs"
   },
   "outputs": [],
   "source": [
    "#========== TESTING PREDICTION ================ ================================\n",
    "# ========= DK 2 UK Translation =============== ================================\n",
    "# We want to feed it DK sentence and let it translation into UK\n",
    "# What would the final version be for the research paper???? UK to Many???\n",
    "#===============================================================================\n",
    "# So far so good ... now how to Predict and get out the stuff that I want?\n",
    "\n",
    "#print('Word list UK: ', english_fit2text.word_index)\n",
    "#print('Word list DK: ', danish_fit2text.word_index)\n",
    "\n",
    "#targ_lang <- UK\n",
    "#inp_lang <- DK\n",
    "\n",
    "# Calculate max_length of the target tensors\n",
    "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)\n",
    "\n",
    "print('='*100)\n",
    "\n",
    "print(max_length_inp)\n",
    "\n",
    "print('='*100)\n",
    "text_testing_dk = 'der var stilhed'\n",
    "#add <start> and <end>\n",
    "sentence = preprocess_sentence(text_testing_dk)\n",
    "print(sentence)\n",
    "inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                           maxlen=max_length_inp,\n",
    "                                                           padding='post')\n",
    "inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "print(inputs)\n",
    "print('='*100)\n",
    "\n",
    "\n",
    "print('='*100)\n",
    "testing_txt2seq_dk = inp_lang.texts_to_sequences(text_testing_dk)\n",
    "print('testing_txt2seq_dk: ', testing_txt2seq_dk)\n",
    "#print('testing_txt2seq dk: ', np.transpose(testing_txt2seq_dk))\n",
    "\n",
    "print('='*100)\n",
    "# What do I want to prove here - that I can go back?\n",
    "testing_seq2txt = inp_lang.sequences_to_texts(testing_txt2seq_dk)\n",
    "print('testing_seq2txt dk: ', testing_seq2txt)\n",
    "\n",
    "print('='*100)\n",
    "\n",
    "#===============================================================================\n",
    "#testing_txt2seq_pad_dk = pad(testing_txt2seq_dk, max_sequence_length)\n",
    "#testing_txt2seq_pad_uk = pad(testing_txt2seq_uk, max_sequence_length)\n",
    "\n",
    "#print('testing_txt2seq_pad dk: ', testing_txt2seq_pad_dk)\n",
    "#print('testing_txt2seq_pad uk: ', testing_txt2seq_pad_uk)\n",
    "print('='*100)\n",
    "#print('Shape dk: ', testing_txt2seq_pad_dk.shape)\n",
    "#print('Shape uk: ', testing_txt2seq_pad_uk.shape)\n",
    "#testing_txt2seq_reshaped = testing_txt2seq_pad.reshape((-1, testing_txt2seq_pad[-1]))\n",
    "print('='*100)\n",
    "\n",
    "#testing_txt2seq_reshaped_dk = testing_txt2seq_pad_dk.reshape(*testing_txt2seq_pad_dk.shape, 1)\n",
    "#testing_txt2seq_reshaped_uk = testing_txt2seq_pad_uk.reshape(*testing_txt2seq_pad_uk.shape, 1)\n",
    "\n",
    "max_sequence_length = input_tensor.shape[1]\n",
    "testing_txt2seq_pad_dk = pad(testing_txt2seq_dk, max_sequence_length)\n",
    "\n",
    "testing_txt2seq_reshaped_dk = testing_txt2seq_pad_dk.reshape(2,max_sequence_length,1)\n",
    "testing_txt2seq_reshaped_uk = testing_txt2seq_pad_uk.reshape(2,max_sequence_length,1)\n",
    "\n",
    "\n",
    "print('testing_txt2seq_reshaped: ', testing_txt2seq_reshaped_dk.shape)\n",
    "print('testing_txt2seq_reshaped_uk: ', testing_txt2seq_reshaped_uk.shape)\n",
    "print('='*100)\n",
    "\n",
    "#======================================================================================\n",
    "dims2 = train_test.predict(testing_txt2seq_dk) #<---- What is the input UK , DK ???\n",
    "print(dims2)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "GoogleVersion_Rebuilding_v2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
